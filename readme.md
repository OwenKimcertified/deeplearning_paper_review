### batch normalization 

출처 : https://arxiv.org/abs/1502.03167

2022 / 11 / 21

Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift

1, 2 페이지 학습. (최종 정리는 끝난 후 일괄 업로드)

2022 / 11 / 24

3, 4, 5, 6 페이지 학습

분포를 어떻게 이동시킬거야? 그로 인한 선형성 문제는?

다중 공선성에도 robust

lr 높게 잡아도 ok, [drop out, regularizer] 안써도 괜찮을 것. 

CNN Batch normalization 

예제 코드 분포 이동 보여주기. 

11 / 26 리뷰 업데이트
-> 완료
